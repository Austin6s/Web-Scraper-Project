{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7964daf3",
   "metadata": {},
   "source": [
    "#  Welcome to my Web Scraper Project\n",
    "\n",
    "## Project objectives:\n",
    "\n",
    "1. Web scrape an ecommerce site to collect the desired data from a product\n",
    "2. Clean that data into a more desirable format\n",
    "3. Export that data into a csv file\n",
    "4. Write a function that uses a timer to automatically append the csv file\n",
    "5. Write a function that sends an email when the price has dropped below a desired price point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import smtplib\n",
    "import time\n",
    "import datetime\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90596c61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Connect to website\n",
    "\n",
    "URL = 'https://spikeball.com/collections/best-sellers/products/spikeball-pro-set'\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36\"}\n",
    "\n",
    "page = requests.get(URL, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "#Collect the data that we want\n",
    "\n",
    "title = soup.find('h1', class_='product-info-title').get_text()\n",
    "\n",
    "price = soup.find('p', class_='price').get_text()\n",
    "\n",
    "rating = soup.find('span', class_=\"stamped-summary-text-1\").get_text()\n",
    "\n",
    "\n",
    "print(title)\n",
    "print(price)\n",
    "print(rating + ' out of 5 stars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a453116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up data points for easier use later\n",
    "\n",
    "title0 = title.strip()\n",
    "price0 = float(price.strip()[1:-4])\n",
    "\n",
    "print(title0)\n",
    "print(price0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b04eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take a timestamp to know when we last collected this data\n",
    "\n",
    "today = datetime.date.today()\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f397ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create and write to a csv file\n",
    "\n",
    "header = ['Date', 'Title', 'Price', 'Rating']\n",
    "data = [today, title0, price0, rating]\n",
    "\n",
    "with open('SpikeballWebScraperDataset.csv', 'w', newline='', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb82d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv into pandas dataframe to read here without having to open the csv file\n",
    "\n",
    "df = pd.read_csv('SpikeballWebScraperDataset.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36857e",
   "metadata": {},
   "source": [
    "### The above code was just to walk through the process and create the initial csv file. Once the csv is created, only the below code needs to be run. Running the above code will recreate the csv file and overwrite any data that may have been stored there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc9455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine all of the above code into one function that appends the csv by adding a new row\n",
    "\n",
    "def check_price():\n",
    "    URL = 'https://spikeball.com/collections/best-sellers/products/spikeball-pro-set'\n",
    "\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.82 Safari/537.36\"}\n",
    "\n",
    "    page = requests.get(URL, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "#Collect the data that we want\n",
    "\n",
    "    title = soup.find('h1', class_='product-info-title').get_text()\n",
    "\n",
    "    price = soup.find('p', class_='price').get_text()\n",
    "\n",
    "    rating = soup.find('span', class_=\"stamped-summary-text-1\").get_text()\n",
    "\n",
    "#Clean up data points for easier use later\n",
    "\n",
    "    title0 = title.strip()\n",
    "    price0 = float(price.strip()[1:-4])\n",
    "\n",
    "#Take a timestamp to know when we last collected this data\n",
    "\n",
    "    today = datetime.date.today()\n",
    "\n",
    "#Write to a csv file\n",
    "\n",
    "    header = ['Date', 'Title', 'Price', 'Rating']\n",
    "    data = [today, title0, price0, rating]\n",
    "\n",
    "#Now we are appending data to the csv\n",
    "\n",
    "    with open('SpikeballWebScraperDataset.csv', 'a+', newline='', encoding='UTF8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)\n",
    "        \n",
    "#Sends me an email if the price drops below $100\n",
    "\n",
    "    if price0 < 100:\n",
    "        send_email()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs check_price after a set time and inputs data into the CSV (let's say once a day in this example)\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "#In seconds, there are 86,400 seconds in a day\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv into pandas dataframe to once again display the data without having to open the CSV\n",
    "\n",
    "df = pd.read_csv('SpikeballWebScraperDataset.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1848030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizes the smtplib package to send an email to myself (just for fun) when a price hits below a certain level\n",
    "\n",
    "def send_email():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('email@gmail.com', 'email_password')\n",
    "    \n",
    "    subject = \"The Spikeball Pro Kit is below $100! Now is your chance to buy!\"\n",
    "    body = \"(Insert person name), this is the moment you have been waiting for. Click this link here to buy now: https://spikeball.com/collections/best-sellers/products/spikeball-pro-set\"\n",
    "   \n",
    "    msg = \"Subject: {}\\n\\n{}\".format(subject, body)\n",
    "    print(msg)\n",
    "    \n",
    "    server.sendmail('email@gmail.com', 'emailyouwanttosendto@gmail.com', msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
